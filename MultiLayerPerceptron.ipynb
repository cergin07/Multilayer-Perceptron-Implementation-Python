{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN61P67fF0PIdM5LVOeClol",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cergin07/Multilayer-Perceptron-Implementation-Python/blob/main/MultiLayerPerceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVftuLfjPVEy"
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split \n",
        "from keras.datasets import mnist\n",
        "import keras\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8XolIk-Pbs6"
      },
      "source": [
        "def normalize(X, axis=-1, order=2):\n",
        "    \"\"\" Normalize the dataset X \"\"\"\n",
        "    l2 = np.atleast_1d(np.linalg.norm(X, order, axis))\n",
        "    l2[l2 == 0] = 1\n",
        "    return X / np.expand_dims(l2, axis)\n",
        "\n",
        "\n",
        "########################################################################\n",
        "\n",
        "def to_categorical(x, n_col=None):\n",
        "    \"\"\" One-hot encoding of nominal values \"\"\"\n",
        "    if not n_col:\n",
        "        n_col = np.amax(x) + 1\n",
        "    one_hot = np.zeros((x.shape[0], n_col))\n",
        "    one_hot[np.arange(x.shape[0]), x] = 1\n",
        "    return one_hot\n",
        "\n",
        "\n",
        "########################################################################\n",
        "\n",
        "def accuracy_score(y_true, y_pred):\n",
        "   \n",
        "    accuracy = np.sum(y_true == y_pred, axis=0) / len(y_true)\n",
        "    return accuracy\n",
        "\n",
        "########################################################################\n",
        "\n",
        "class CrossEntropy():\n",
        "    def __init__(self): pass\n",
        "\n",
        "    def loss(self, y, p):\n",
        "        # Avoid division by zero\n",
        "        p = np.clip(p, 1e-15, 1 - 1e-15)\n",
        "        return - y * np.log(p) - (1 - y) * np.log(1 - p)\n",
        "\n",
        "    def acc(self, y, p):\n",
        "        return accuracy_score(np.argmax(y, axis=1), np.argmax(p, axis=1))\n",
        "\n",
        "    def gradient(self, y, p):\n",
        "        # Avoid division by zero\n",
        "        p = np.clip(p, 1e-15, 1 - 1e-15)\n",
        "        return - (y / p) + (1 - y) / (1 - p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHKkGVXzPfz6"
      },
      "source": [
        "class Sigmoid():\n",
        "    def __call__(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def gradient(self, x):\n",
        "        return self.__call__(x) * (1 - self.__call__(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qh1Rp8GLPhO4"
      },
      "source": [
        "class Softmax():\n",
        "    def __call__(self, x):\n",
        "        e_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
        "        return e_x / np.sum(e_x, axis=-1, keepdims=True)\n",
        "\n",
        "    def gradient(self, x):\n",
        "        p = self.__call__(x)\n",
        "        return p * (1 - p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_kX19ZYP-tH"
      },
      "source": [
        "class MultilayerPerceptron():\n",
        "\n",
        "    def __init__(self, n_hidden, n_iterations=3000, learning_rate=0.01):\n",
        "        self.n_hidden = n_hidden\n",
        "        self.n_iterations = n_iterations\n",
        "        self.learning_rate = learning_rate\n",
        "        self.hidden_activation = Sigmoid()\n",
        "        self.output_activation = Softmax()\n",
        "        self.loss = CrossEntropy()\n",
        "\n",
        "    def _initialize_weights(self, X, y):\n",
        "        \n",
        "        n_samples, n_features = X.shape\n",
        "        _, n_outputs = y.shape\n",
        "        \n",
        "        # Hidden layer\n",
        "        limit   = 1 / math.sqrt(n_features)\n",
        "        self.W  = np.random.uniform(-limit, limit, (n_features, self.n_hidden))\n",
        "        self.w0 = np.zeros((1, self.n_hidden))\n",
        "        \n",
        "        # Output layer\n",
        "        limit   = 1 / math.sqrt(self.n_hidden)\n",
        "        self.V  = np.random.uniform(-limit, limit, (self.n_hidden, n_outputs))\n",
        "        self.v0 = np.zeros((1, n_outputs))\n",
        "\n",
        "    def fit(self, X, y):\n",
        "\n",
        "        self._initialize_weights(X, y)\n",
        "\n",
        "        for i in range(self.n_iterations):\n",
        "\n",
        "            # ..............\n",
        "            #  Forward Pass\n",
        "            # ..............\n",
        "\n",
        "            # HIDDEN LAYER\n",
        "            hidden_input = X.dot(self.W) + self.w0\n",
        "            hidden_output = self.hidden_activation(hidden_input)\n",
        "            # OUTPUT LAYER\n",
        "            output_layer_input = hidden_output.dot(self.V) + self.v0\n",
        "            y_pred = self.output_activation(output_layer_input)\n",
        "            \n",
        "            ############################################################\n",
        "\n",
        "            # ...............\n",
        "            #  Backward Pass\n",
        "            # ...............\n",
        "\n",
        "            # OUTPUT LAYER\n",
        "            # Grad. with respect to input of output layer\n",
        "            grad_wrt_out_l_input = self.loss.gradient(y, y_pred) * self.output_activation.gradient(output_layer_input)\n",
        "            grad_v = hidden_output.T.dot(grad_wrt_out_l_input)\n",
        "            grad_v0 = np.sum(grad_wrt_out_l_input, axis=0, keepdims=True)\n",
        "            \n",
        "            # HIDDEN LAYER\n",
        "            # Grad. with respect to input of hidden layer\n",
        "            grad_wrt_hidden_l_input = grad_wrt_out_l_input.dot(self.V.T) * self.hidden_activation.gradient(hidden_input)\n",
        "            grad_w = X.T.dot(grad_wrt_hidden_l_input)\n",
        "            grad_w0 = np.sum(grad_wrt_hidden_l_input, axis=0, keepdims=True)\n",
        "            \n",
        "            ############################################################\n",
        "\n",
        "            # Update weights (by gradient descent)\n",
        "            # Move against the gradient to minimize loss\n",
        "            self.V  -= self.learning_rate * grad_v\n",
        "            self.v0 -= self.learning_rate * grad_v0\n",
        "            self.W  -= self.learning_rate * grad_w\n",
        "            self.w0 -= self.learning_rate * grad_w0\n",
        "            \n",
        "    \n",
        "    def predict(self, X):\n",
        "        hidden_input = X.dot(self.W) + self.w0\n",
        "        hidden_output = self.hidden_activation(hidden_input)\n",
        "        output_layer_input = hidden_output.dot(self.V) + self.v0\n",
        "        y_pred = self.output_activation(output_layer_input)\n",
        "        return y_pred\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PuYUGDxQA_Y",
        "outputId": "e3ba364c-c513-4e0a-f657-2255c7d20a19"
      },
      "source": [
        "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
        "train_X=train_X.reshape(train_X.shape[0],784).astype('float32')\n",
        "test_X=test_X.reshape(test_X.shape[0],784).astype('float32')\n",
        "\n",
        "train_y=to_categorical(train_y)\n",
        "test_y=to_categorical(test_y)\n",
        "\n",
        "\n",
        "\n",
        "test_X /=255\n",
        "train_X /=255\n",
        "\n",
        "\n",
        "\n",
        "#data = datasets.load_digits()\n",
        "\n",
        "#y = data.target\n",
        "#y = to_categorical(y)\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
        "\n",
        "print(train_X.shape)\n",
        "print(train_y.shape)\n",
        "print(test_X.shape)\n",
        "print(test_y.shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 784)\n",
            "(60000, 10)\n",
            "(10000, 784)\n",
            "(10000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QH2tpSQQDKo",
        "outputId": "faba3fa5-ec50-453e-efe5-59bd8a9646a7"
      },
      "source": [
        "clf = MultilayerPerceptron(n_hidden=28, n_iterations=1000, learning_rate=0.01)\n",
        "\n",
        "clf.fit(train_X, train_y)\n",
        "\n",
        "#########################################################\n",
        "    \n",
        "y_pred = np.argmax(clf.predict(test_X), axis=1)\n",
        "y_test = np.argmax(test_y, axis=1)\n",
        "\n",
        "#########################################################\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print (\"Accuracy:\", accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.101\n"
          ]
        }
      ]
    }
  ]
}